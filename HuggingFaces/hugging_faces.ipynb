{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Working with Hugging Faces",
   "id": "9a5e1ddf7beaf920"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Listing Models",
   "id": "8f6b8b5b596f83b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Create an instance of the HfApi class\n",
    "api = HfApi()\n",
    "\n",
    "# List only the first 2 models available on the Hub\n",
    "models = list(api.list_models(limit=2))\n",
    "\n",
    "# Print the first 2 models\n",
    "for model in models:\n",
    "    print(model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Building a Text Pipeline",
   "id": "8359b4c96c53165f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "my_pipeline = pipeline(task=\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "# Generate three text outputs with a maximum length of 10 tokens\n",
    "results = my_pipeline(\"one, two, three\", max_length=10, num_return_sequences=3)\n",
    "\n",
    "# Display each result\n",
    "for result in results:\n",
    "    print(result['generated_text'])"
   ],
   "id": "520b175e624208f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a pipeline for grammar checking",
   "id": "646dea6eea22ae83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "grammar_checker = pipeline(\n",
    "  task=\"text-classification\",\n",
    "  model=\"abdulmatinomotoso/English_Grammar_Checker\"\n",
    ")\n",
    "\n",
    "output = grammar_checker(\"I will walk dog\")\n",
    "print(output)"
   ],
   "id": "eb22a25e9844aa4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dynamic category assignment",
   "id": "16b9f258cfa63173"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "text = \"AI-powered robots assist in complex brain surgeries with precision.\"\n",
    "\n",
    "# Create the pipeline\n",
    "classifier = pipeline(task=\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Create the categories list\n",
    "categories = [\"politics\", \"science\", \"sports\"]\n",
    "\n",
    "# Predict the output\n",
    "output = classifier(text, categories)\n",
    "\n",
    "# Print the top label and its score\n",
    "print(f\"Top Label: {output['labels'][0]} with score: {output['scores'][0]}\")"
   ],
   "id": "4317e0dba54160d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Text Summarization",
   "id": "54a277128b74a944"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "original_text = \"\"\"In the field of artificial intelligence, text summarization is a crucial task that involves condensing a large body of text into a shorter version while retaining its key information and overall meaning. This process is particularly useful in various applications such as news aggregation, document summarization, and content curation.\n",
    "Text summarization can be broadly categorized into two types: extractive and abstractive summarization. Extractive summarization involves selecting and extracting key sentences or phrases from the original text, while abstractive summarization generates new sentences that capture the essence of the original content.\n",
    "Abstractive summarization is often more challenging as it requires a deeper understanding of the text and the ability to generate coherent and contextually relevant sentences. Recent advancements in natural language processing, particularly with the development of transformer-based models, have significantly improved the performance of both extractive and abstractive summarization techniques.\"\"\"\n",
    "summarizer = pipeline(task=\"summarization\", model=\"cnicu/t5-small-booksum\")\n",
    "\n",
    "summary_text = summarizer(original_text)\n",
    "\n",
    "# Compare the length\n",
    "print(f\"Original text length: {len(original_text)}\")\n",
    "print(f\"Summary length: {len(summary_text[0]['summary_text'])}\")"
   ],
   "id": "8108601023763307"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenizing text with AutoTokenizer",
   "id": "919476c27c28208c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Split input text into tokens\n",
    "tokens = tokenizer.tokenize(\"AI: Making robots smarter and humans lazier!\")\n",
    "\n",
    "print(f\"Tokenized output: {tokens}\")"
   ],
   "id": "89fc2b824474f0b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Using AutoClasses",
   "id": "f18ccbe252390de9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "my_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "my_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Create the pipeline\n",
    "my_pipeline = pipeline(task=\"sentiment-analysis\", model=my_model, tokenizer=my_tokenizer)\n",
    "\n",
    "# Predict the sentiment\n",
    "output = my_pipeline(\"This course is pretty good, I guess.\")\n",
    "print(f\"Sentiment using AutoClasses: {output[0]['label']}\")"
   ],
   "id": "a19c4caea6af95dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
