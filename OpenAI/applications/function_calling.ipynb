{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Function Calling with OpenAI API\n",
    "#### This notebook demonstrates how to use the OpenAI API for function calling, including loading the API key, initializing the API client, and making requests with structured messages."
   ],
   "id": "a56d264b24d017bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading OpenAI API Key",
   "id": "2443ebe82994578b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T06:50:02.344811Z",
     "start_time": "2025-07-28T06:50:02.342055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path='../../.env')  # Specify the path to your .env file\n",
    "\n",
    "# Access the environment variable\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check if the variable is loaded\n",
    "if api_key or api_key == \"\":\n",
    "    print(\"API key loaded successfully.\")\n",
    "else:\n",
    "    print(\"Failed to load API key.\")"
   ],
   "id": "1687d4cc23c58518",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully.\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initializing OpenAI API",
   "id": "a983dd262a2e0243"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T06:50:02.360220Z",
     "start_time": "2025-07-28T06:50:02.355210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ],
   "id": "c78451f0857525b7",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Auxiliary Functions",
   "id": "5f03cac9c5ba5c83"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Function to get the model response",
   "id": "86607d47058d2a05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T06:50:02.368106Z",
     "start_time": "2025-07-28T06:50:02.366032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Message:\n",
    "    def __init__(self, role, content):\n",
    "        self.role = role\n",
    "        self.content = content\n",
    "\n",
    "class FunctionDef:\n",
    "    def __init__(self, name, description, parameters):\n",
    "        self.type = \"function\"\n",
    "        self.function = {\n",
    "            \"name\": name,\n",
    "            \"description\": description,\n",
    "            \"parameters\": parameters\n",
    "        }\n"
   ],
   "id": "bb23438284e02594",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T06:50:02.375876Z",
     "start_time": "2025-07-28T06:50:02.373741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "@retry(wait=(wait_random_exponential(min=5, max=40)), stop=stop_after_attempt(4))\n",
    "def get_response(req_msgs:list[Message], tools: list[FunctionDef], model=\"gpt-4o-mini\", temperature=0.7):\n",
    "    \"\"\"\n",
    "    Get a response from the OpenAI API.\n",
    "\n",
    "    Parameters:\n",
    "    - prompt (str): The input prompt for the model.\n",
    "    - model (str): The model to use.\n",
    "    - temperature (float): Sampling temperature. Default is 0.7.\n",
    "\n",
    "    Returns:\n",
    "    - str: The model's response.\n",
    "    \"\"\"\n",
    "    model_response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[message.__dict__ for message in req_msgs],\n",
    "        temperature=temperature,\n",
    "        tools=[tool.__dict__ for tool in tools],\n",
    "        response_format={ \"type\": \"json_object\" }\n",
    "    )\n",
    "    return model_response"
   ],
   "id": "ef0ae60e6c6506da",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T06:50:02.384687Z",
     "start_time": "2025-07-28T06:50:02.381575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "\n",
    "class MessageLengthError(Exception):\n",
    "    \"\"\"Custom exception for message length errors.\"\"\"\n",
    "    def __init__(self, errors:[], message=\"Message length validation failed.\"):\n",
    "        \"\"\"\n",
    "        Initialize the MessageLengthError exception.\n",
    "        :param errors:\n",
    "        :param message:\n",
    "        \"\"\"\n",
    "        self.errors = errors\n",
    "        super().__init__(message)\n",
    "\n",
    "    def get_errors(self):\n",
    "        \"\"\"\n",
    "        Get the list of errors.\n",
    "        :return: List of errors.\n",
    "        \"\"\"\n",
    "        return self.errors\n",
    "\n",
    "def count_tokens(input_message: Message):\n",
    "    \"\"\"\n",
    "    Count the number of tokens in a message.\n",
    "\n",
    "    Parameters:\n",
    "    - input_message (Message): The message to count tokens for.\n",
    "\n",
    "    Returns:\n",
    "    - int: The number of tokens in the message.\n",
    "    \"\"\"\n",
    "    my_encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "    return len(my_encoding.encode(input_message.content))\n",
    "\n",
    "def validate_messages(msgs_to_validate: list[Message], max_total_tokens=4096, max_tokens_per_message=2048):\n",
    "    \"\"\"\n",
    "    Validate the messages to ensure they do not exceed the token limit.\n",
    "\n",
    "    Parameters:\n",
    "    - messages (list[Message]): The list of messages to validate.\n",
    "    - max_tokens (int): The maximum number of tokens allowed. Default is 4096.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    total_tokens = 0\n",
    "    for i, message in enumerate(msgs_to_validate):\n",
    "        msg_tokens = count_tokens(message)\n",
    "        total_tokens += msg_tokens\n",
    "        if msg_tokens > max_tokens_per_message:\n",
    "            errors.append(f\"Message {i+1} exceeds token limit: {msg_tokens} tokens (max {max_tokens_per_message} tokens)\")\n",
    "\n",
    "    if total_tokens > max_total_tokens:\n",
    "        errors.append(f\"Total tokens exceed limit: {total_tokens} tokens (max {max_total_tokens} tokens)\")\n",
    "\n",
    "    if len(errors) > 0:\n",
    "        raise MessageLengthError(errors=errors, message=\"Message length validation failed.\")\n",
    "\n"
   ],
   "id": "399d5adcbf5cc091",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Examples",
   "id": "6ee5ffd3fc33801f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T06:50:04.730086Z",
     "start_time": "2025-07-28T06:50:02.390032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "books = \"The Great Gatsby, To Kill a Mockingbird, 1984, Pride and Prejudice, The Catcher in the Rye\"\n",
    "prompt = f\"For each book in {books} find the author and the year of publication, and return the results in a JSON format.\"\n",
    "messages = [Message(role=\"user\", content=prompt)]\n",
    "tools = [\n",
    "    FunctionDef(\n",
    "        name=\"get_book_info\",\n",
    "        description=\"Get the author and year of publication for a book.\",\n",
    "        parameters={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"book\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the book.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"book\"]\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "response = get_response(req_msgs=messages, tools=tools)\n",
    "\n",
    "# Print the response content\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# Print the tool calls made by the model\n",
    "for tool_call in response.choices[0].message.tool_calls:\n",
    "    print(f\"Tool called: {tool_call.function.name}\")\n",
    "    print(f\"Arguments: {tool_call.function.arguments}\")\n",
    "\n",
    "\n"
   ],
   "id": "4304c3399bd64b72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Tool called: get_book_info\n",
      "Arguments: {\"book\": \"The Great Gatsby\"}\n",
      "Tool called: get_book_info\n",
      "Arguments: {\"book\": \"To Kill a Mockingbird\"}\n",
      "Tool called: get_book_info\n",
      "Arguments: {\"book\": \"1984\"}\n",
      "Tool called: get_book_info\n",
      "Arguments: {\"book\": \"Pride and Prejudice\"}\n",
      "Tool called: get_book_info\n",
      "Arguments: {\"book\": \"The Catcher in the Rye\"}\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T06:50:04.739486Z",
     "start_time": "2025-07-28T06:50:04.737503Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ca9169c896f08589",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
